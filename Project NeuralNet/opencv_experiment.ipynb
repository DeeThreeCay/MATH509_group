{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from ipywidgets import interact\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Reading an mp4 file, reading pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File opened:  True\n",
      "Number of frames: 160 frames\n",
      "Size of each frame (height x width): 512 x 512\n"
     ]
    }
   ],
   "source": [
    "mp4_file = '../Project Salmonella/Videos/160706_WT_Q/Duodenum/160706_WT_Q_Duodenum_NoAbAdded_1.mp4'\n",
    "\n",
    "# Open the MP4 file\n",
    "cap = cv2.VideoCapture(mp4_file)\n",
    "print(\"File opened: \", cap.isOpened())\n",
    "\n",
    "# List to store pixel values\n",
    "pixel_values = []\n",
    "thresholded_pixel_values = []\n",
    "threshold = 200\n",
    "\n",
    "# Read frames until the end of the video\n",
    "while(cap.isOpened()):\n",
    "    # Read a frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    corrected_frame_gray = cv2.flip(frame_gray, 0) # re-orienting\n",
    "    _, thresholded_frame_gray = cv2.threshold(corrected_frame_gray, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Convert the frame to a list of lists (pixel values)\n",
    "    frame_pixels = corrected_frame_gray.tolist()\n",
    "    pixel_values.append(frame_pixels)\n",
    "    thresholded_pixel_values.append(thresholded_frame_gray)\n",
    "\n",
    "thresholded_pixel_values_array = np.array(thresholded_pixel_values)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Stats\n",
    "print(\"Number of frames:\", len(pixel_values), \"frames\")\n",
    "print(\"Size of each frame (height x width):\", len(pixel_values[0]), \"x\", len(pixel_values[0][0]))\n",
    "#print(\"Min intensity:\", min(pixel_values))\n",
    "#print(\"Max intensity:\", max(pixel_values))\n",
    "\n",
    "Nt = len(pixel_values)\n",
    "height = len(pixel_values[0])\n",
    "width = len(pixel_values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d06fa5149c1d4d0fa4df98891cb74243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='t', max=159), Checkbox(value=True, description='show_tra…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(t=(0, Nt-1, 1))\n",
    "def plotfn(t=0, show_tracks=True):\n",
    "    fig = figure(1, [12, 6])\n",
    "    fig.add_subplot(121)\n",
    "    imshow(pixel_values[t], origin='lower')\n",
    "    title(\"Original video\")\n",
    "    xlim(0, width)\n",
    "    ylim(0, height)\n",
    "\n",
    "    fig.add_subplot(122)\n",
    "    imshow(thresholded_pixel_values_array[t], origin='lower')\n",
    "    title(\"Threshold = 100\")\n",
    "    xlim(0, width)\n",
    "    ylim(0, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4ec77222264ca6a9eb1167d0b7c297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='t', max=159), Checkbox(value=True, description='show_tra…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(t=(0, Nt-1, 1))\n",
    "def plotfn(t=0, show_tracks=True):\n",
    "    fig = figure(1, [12, 6])\n",
    "    fig.add_subplot(121)\n",
    "    imshow(pixel_values[t], origin='lower')\n",
    "    title(\"Original video\")\n",
    "    xlim(0, width)\n",
    "    ylim(0, height)\n",
    "\n",
    "    fig.add_subplot(122)\n",
    "    imshow(thresholded_pixel_values_array[t], origin='lower')\n",
    "    title(\"Threshold = 150\")\n",
    "    xlim(0, width)\n",
    "    ylim(0, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b816e82f26416ab6c4601a5b6e57e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='t', max=159), Checkbox(value=True, description='show_tra…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(t=(0, Nt-1, 1))\n",
    "def plotfn(t=0, show_tracks=True):\n",
    "    fig = figure(1, [12, 6])\n",
    "    fig.add_subplot(121)\n",
    "    imshow(pixel_values[t], origin='lower')\n",
    "    title(\"Original video\")\n",
    "    xlim(0, width)\n",
    "    ylim(0, height)\n",
    "\n",
    "    fig.add_subplot(122)\n",
    "    imshow(thresholded_pixel_values_array[t], origin='lower')\n",
    "    title(\"Threshold = 180\")\n",
    "    xlim(0, width)\n",
    "    ylim(0, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec92e942cf764f2db73cba73a8ba4641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='t', max=159), Checkbox(value=True, description='show_tra…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(t=(0, Nt-1, 1))\n",
    "def plotfn(t=0, show_tracks=True):\n",
    "    fig = figure(1, [12, 6])\n",
    "    fig.add_subplot(121)\n",
    "    imshow(pixel_values[t], origin='lower')\n",
    "    title(\"Original video\")\n",
    "    xlim(0, width)\n",
    "    ylim(0, height)\n",
    "\n",
    "    fig.add_subplot(122)\n",
    "    imshow(thresholded_pixel_values_array[t], origin='lower')\n",
    "    title(\"Threshold = 200\")\n",
    "    xlim(0, width)\n",
    "    ylim(0, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaway message\n",
    "\n",
    "1) With **low thresholding**: Noise would be included\n",
    "2) With **high thresholding**: Some true particles would be neglected\n",
    "3) Thresholding also does **not** give insights on movement tracking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
